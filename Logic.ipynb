{"cells":[{"cell_type":"code","execution_count":161,"id":"216dc1f9","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+------+------+-------+------+-------+-------------------------------------+\n","|timestamp |open  |high  |low    |close |volume |filename                             |\n","+----------+------+------+-------+------+-------+-------------------------------------+\n","|2022-03-15|129.22|131.15|128.865|130.28|1649205|gs://terradataproc-bucket-53533/A.txt|\n","|2022-03-14|131.0 |132.26|126.9  |127.58|1737149|gs://terradataproc-bucket-53533/A.txt|\n","|2022-03-11|135.43|136.44|130.16 |130.31|1815769|gs://terradataproc-bucket-53533/A.txt|\n","|2022-03-10|131.4 |134.52|131.29 |134.33|1933127|gs://terradataproc-bucket-53533/A.txt|\n","|2022-03-09|132.85|133.94|131.19 |133.26|1805585|gs://terradataproc-bucket-53533/A.txt|\n","|2022-03-08|128.64|132.5 |127.54 |129.32|2375483|gs://terradataproc-bucket-53533/A.txt|\n","|2022-03-07|133.55|133.55|128.43 |130.34|2376504|gs://terradataproc-bucket-53533/A.txt|\n","|2022-03-04|135.85|137.12|132.14 |133.89|3848511|gs://terradataproc-bucket-53533/A.txt|\n","|2022-03-03|133.73|138.0 |133.44 |137.17|3592139|gs://terradataproc-bucket-53533/A.txt|\n","|2022-03-02|132.68|133.96|131.8  |133.16|1863110|gs://terradataproc-bucket-53533/A.txt|\n","+----------+------+------+-------+------+-------+-------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["from  pyspark.sql.functions import input_file_name\n","from pyspark.sql.functions  import regexp_extract\n","from pyspark.sql.functions import regexp_extract, col, split, size\n","from pyspark.sql import *\n","from pyspark.conf import SparkConf\n","SparkSession.builder.config(conf=SparkConf())\n","# A=spark.read.options(header='True',inferSchema='True',delimiter=',').csv(\"A.txt\")\n","# b=A.withColumn(\"filename\", input_file_name())\n","# b.show(10, False)"]},{"cell_type":"code","execution_count":125,"id":"8d56eb2b","metadata":{},"outputs":[],"source":["#Extract file name as column\n","def extract_filename(tableDF):\n","    b=tableDF.withColumn(\"filename\", regexp_extract(input_file_name(), r'(?<=.*\\/.*\\/.*\\/).+', 0))\n","    c=b.withColumn(\"Symbol1\", regexp_extract(\"filename\", r'^([^.])+', 0))\n","    #print(c)\n","    return(c)\n"]},{"cell_type":"code","execution_count":140,"id":"d21716f3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["5616\n","root\n"," |-- timestamp: string (nullable = true)\n"," |-- open: double (nullable = true)\n"," |-- high: double (nullable = true)\n"," |-- low: double (nullable = true)\n"," |-- close: double (nullable = true)\n"," |-- volume: integer (nullable = true)\n"," |-- filename: string (nullable = false)\n"," |-- Symbol1: string (nullable = false)\n","\n","1361\n","root\n"," |-- timestamp: string (nullable = true)\n"," |-- open: double (nullable = true)\n"," |-- high: double (nullable = true)\n"," |-- low: double (nullable = true)\n"," |-- close: double (nullable = true)\n"," |-- volume: integer (nullable = true)\n"," |-- filename: string (nullable = false)\n"," |-- Symbol1: string (nullable = false)\n","\n","root\n"," |-- Symbol: string (nullable = true)\n"," |-- Name: string (nullable = true)\n"," |-- Country: string (nullable = true)\n"," |-- Sector: string (nullable = true)\n"," |-- Industry: string (nullable = true)\n"," |-- Address: string (nullable = true)\n","\n"]}],"source":["#Read diff csv files and craete new column called symbol by passing \n","#the df to above function to add filename in the symbol col to join with meta table\n","#due to huge amount of files, I just took only 2 files but can add all the files sent to the above function\n","A=spark.read.options(header='True',inferSchema='True',delimiter=',').csv(\"A.txt\")\n","A=extract_filename(A)\n","print(A.count())\n","A.printSchema()\n","\n","AA=spark.read.options(header='True',inferSchema='True',delimiter=',').csv(\"AA.txt\")\n","AA=extract_filename(AA)\n","print(AA.count())\n","AA.printSchema()\n","\n","metadata=spark.read.options(header='True',inferSchema='True',delimiter=',').csv(\"meta_sample.txt\")\n","metadata.printSchema()\n","\n","#df.withColumn(\"filename\", input_file_name()).show(10, False)"]},{"cell_type":"code","execution_count":151,"id":"eb624e9f","metadata":{},"outputs":[],"source":["unoindfs=A.union(AA)\n","unionplusjoin=unoindfs.join(metadata, unoindfs['Symbol1'] == metadata['Symbol'], \"inner\")\n"]},{"cell_type":"code","execution_count":156,"id":"f85f6453","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 297:============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------+------------------+------------------+--------------+-------------+------------------+\n","|Sector       |Avg_Open_Price    |Avg_Close_Price   |Max_High_Price|Min_Low_Price|Avg_Volume        |\n","+-------------+------------------+------------------+--------------+-------------+------------------+\n","|LIFE SCIENCES|48.928510505698235|48.939718660968595|179.57        |10.5         |2710846.7519586897|\n","|MANUFACTURING|32.826966348273345|32.84054371785455 |92.32         |5.16         |5396276.952240999 |\n","+-------------+------------------+------------------+--------------+-------------+------------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#report 1 Generate summary reports for all time till yesterday\n","from pyspark.sql.functions import *\n","report1=unionplusjoin.groupBy(\"Sector\") \\\n","       .agg(avg(\"open\").alias(\"Avg_Open_Price\"), \\\n","            avg(\"close\").alias(\"Avg_Close_Price\"), \\\n","            max(\"high\").alias(\"Max_High_Price\"), \\\n","            min(\"low\").alias(\"Min_Low_Price\"), \\\n","            avg(\"volume\").alias(\"Avg_Volume\"))\n","report1.show(20, False)"]},{"cell_type":"code","execution_count":159,"id":"0f3b52b9","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 311:============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------+------------------+------------------+--------------+-------------+----------+\n","|Sector       |Avg_Open_Price    |Avg_Close_Price   |Max_High_Price|Min_Low_Price|Avg_Volume|\n","+-------------+------------------+------------------+--------------+-------------+----------+\n","|LIFE SCIENCES|127.09909999999999|127.01569999999998|138.0         |112.47       |1626721.94|\n","|MANUFACTURING|29.425661000000012|29.48590000000001 |44.42         |17.3         |6822501.93|\n","+-------------+------------------+------------------+--------------+-------------+----------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#report 2 Generate summary reports for the given period of time\n","\n","filter_days=unionplusjoin.filter(\"timestamp between '2021-01-01' and '2021-05-26'\")\n","\n","report2=filter_days.groupBy(\"Sector\") \\\n","       .agg(avg(\"open\").alias(\"Avg_Open_Price\"), \\\n","            avg(\"close\").alias(\"Avg_Close_Price\"), \\\n","            max(\"high\").alias(\"Max_High_Price\"), \\\n","            min(\"low\").alias(\"Min_Low_Price\"), \\\n","            avg(\"volume\").alias(\"Avg_Volume\"))\n","report2.show(20, False)"]},{"cell_type":"code","execution_count":160,"id":"63f2c24c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 317:============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+------+------------------------+------------------+------------------+--------------+-------------+------------------+\n","|Symbol|Name                    |Avg_Open_Price    |Avg_Close_Price   |Max_High_Price|Min_Low_Price|Avg_Volume        |\n","+------+------------------------+------------------+------------------+--------------+-------------+------------------+\n","|A     |Agilent Technologies Inc|128.13925373134327|128.08119402985076|138.0         |112.47       |1569628.7014925373|\n","|AA    |Alcoa Corporation       |33.151807462686584|33.27567164179105 |44.42         |22.95        |7090108.059701492 |\n","+------+------------------------+------------------+------------------+--------------+-------------+------------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#report 3  Generate detailed reports for the given sector + given period of time\n","\n","filter_days_report3=unionplusjoin.filter(\"timestamp between '2021-02-21' and '2021-05-26'\")\n","\n","report3=filter_days_report3.groupBy(\"Symbol\",\"Name\") \\\n","       .agg(avg(\"open\").alias(\"Avg_Open_Price\"), \\\n","            avg(\"close\").alias(\"Avg_Close_Price\"), \\\n","            max(\"high\").alias(\"Max_High_Price\"), \\\n","            min(\"low\").alias(\"Min_Low_Price\"), \\\n","            avg(\"volume\").alias(\"Avg_Volume\"))\n","report3.show(20, False)"]},{"cell_type":"code","execution_count":163,"id":"9a73778f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["#sample output storage code to write gcs\n","\n","report3.write.format(\"csv\").mode(\"append\").save(\"gs://terradataproc-bucket-53533/data.txt\")"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"}},"nbformat":4,"nbformat_minor":5}